CLASS DESIGN
I created juts one class Time_Series. This class represents and manages a time-indexed dataset of (year, value) pairs. It provides all the necessary utility operations on that dataset, including loading, printing, adding, updating, and computing different important values related to the data (such as mean, best fit function etc.). This is important because the project focuses on time series operations. Grouping the data and the rules for handling it into one class results in a clean and logical design.
I also used private variables so that outside classes or programs could not edit critical variables such as last_idx, and array_size, and the arrays themselves directly, thus fulfilling encapsulation. Only methods from this class can directly edit these private variables. Finally, the class methods are all public, and this is because these functions need to be accessible by outside programs in order for them to have certain functionality.
Going deeper into individual method functionality, only one method is used to actually resize the array when needed, the resizeSeries() method, which is called when the checkAndResize method detects that the resize conditions have been met. Therefore checkAndResize acts as a method wrapper which can be called from anywhere inside the code to first check if array size is correct and then resize it if necessary. The last_idx method and array_size variables keep track of array capacity and total storage allocated to it. All other functions, such as insertSeriesElement, and removeSeriesElement, merely rearrange the values in the array.
ALTERNATIVES AND JUSTIFICATION
I initially had a lot more helper methods which turned out to be redundant. Additionally, I had separate template methods which individually resized very array. I later realised I didnâ€™t need such generic functions, and such high levels of abstraction so I removed these from my code, and replaced them with more consolidated versions that, iterate on both arrays contained inside the series at the same time. The main reason the previous solution was invalid, is because in order to have two separate functions iterating on the array, that would have forced me to check array size twice and changed that variable and last_idx variable multiple times. By consolidating everything into one method, I ensured that there was one source of truth for the program. I did this with all the other methods too. This minimized the amount of places where I had to change the array_capacity variable and array_size variables, which vastly improved the debugging speed of the program, as well as also eliminated valgrind errors. Where initially, I had a lot of variables to keep track of everything, I was able to water that down to have a few essential variables and methods that interacted with the array.
RUNTIME ANALYSIS
N is the number of years currently stored in the time series, or in the code: last_idx.
We do the runtime analysis in terms of N.

UPDATE command worst-case runtime is O(N):
UPDATE is implemented by:
void Time_Series::update(int year, double datum){
int idx = returnYearIdx(year);
if (idx < 0 || years[idx] != year){
if (datum < 0){
removeSeriesElement(idx);
...
} else {
data[idx] = datum;
...
}
} else {
...
}
}
Step-by-step analysis:
     returnYearIdx(year)
This function performs a binary search over the sorted years array. Each loop iteration halves the search range, and therefore its worst case runtime is O(log N).
    (datum >= 0)
The operation data[idx] = datum is a single array write. Therefore O(1)
    (datum < 0)
Update method calls removeSeriesElement(idx), which shifts all elements after idx one position left:
for (int i = idx + 1; i < last_idx; i++){
years[i - 1] = years[i];
data[i - 1] = data[i];
}
In the worst case, idx = 0 (removing the first element), so the loop runs from i = 1 to i = N-1. That performs N-1 iterations, each doing O(1) work. This in total means N operations are executed, thus O(N) time.
Putting it together:
Therefore out of all of these branches, the wors case time complexity is:
O(log N) + O(N) + O(1) = O(N)
Therefore, the UPDATE command has worst-case runtime O(N).

MONOTONIC command best-case runtime is O(1)
MONOTONIC is implemented by:
bool Time_Series::is_monotonic() {
if (last_idx == 0) { ... return false; }
    unsigned int j = 0;
    while (j < last_idx && data[j] == MISSING_DATA_INDICATOR) j++;

    if (j == last_idx) { ... return false; }

    unsigned int k = j + 1;
    while (k < last_idx && data[k] == MISSING_DATA_INDICATOR) k++;

    if (k == last_idx) { ... return true; }

    bool nonDecreasing = (data[k] >= data[j]);
    double prev = data[k];

    for (unsigned int i = k + 1; i < last_idx; i++) {
        if (data[i] == MISSING_DATA_INDICATOR) continue;
        if (nonDecreasing) {
            if (data[i] < prev) { ... return false; }
        } else {
            if (data[i] > prev) { ... return false; }
        }
        prev = data[i];
    }

    ... return true;
}
To show O(1) is the best time complexity we give an example where it will finish in such a time complexity.
Below is a best-case scenario example:
1.	last_idx > 0
2.	data[0] is valid, data[1] is valid (not missing)
3.	The third valid data point immediately violates monotonicity:
Example: data[0] = 1, data[1] = 2, data[2] = 0 (non-decreasing chosen, but data[2] < prev)
What happens in this case:
1.	Check last_idx == 0: constant time.
2.	Find first valid j: j = 0 immediately, loop does 0 iterations.
3.	Find second valid k: k = 1 immediately, loop does 0 iterations.
4.	Determine direction: constant time.
5.	Enter for-loop starting at i = 2:
In this best case, the function performs a constant number of checks (a few if statements and comparisons), and exits after examining only the first 3 elements. Therefore, the time complexity is O(1), as it does not grow with the addition of new elements to the series.
